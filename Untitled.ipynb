{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: nl8590687\n",
    "\"\"\"\n",
    "import platform as plat\n",
    "import os\n",
    "import time\n",
    "\n",
    "from general_function.file_wav import *\n",
    "from general_function.file_dict import *\n",
    "from general_function.gen_func import *\n",
    "\n",
    "# LSTM_CNN\n",
    "import keras as kr  #导入keras的包\n",
    "import numpy as np  #导入\n",
    "import random\n",
    "\n",
    "# 从keras模型中导入序贯型以及函数式的模型\n",
    "from keras.models import Sequential, Model\n",
    "# 从神经网络层中导入 全连接层,随机失活,输入层,矩阵维度变换,BN归一化\n",
    "from keras.layers import Dense, Dropout, Input, Reshape, BatchNormalization # , Flatten\n",
    "# 从神经网络层中导入 ,Lambda层(如果你只是想对流经该层的数据做个变换，而这个变换本身没有什么需要学习的参数，那么直接用Lambda Layer是最合适的了。)\n",
    "# imeDistributed这个封装器将一个层应用于输入的每个时间片。\n",
    "# Activation 激活函数\n",
    "# 二维的卷积层\n",
    "# 二维的池化层\n",
    "from keras.layers import Lambda, TimeDistributed, Activation,Conv2D, MaxPooling2D #, Merge\n",
    "# 导入keras的底层框架 这里是TensorFlow\n",
    "from keras import backend as K   \n",
    "# 导入优化器 SGD,Adam\n",
    "# Adagrad会累加之前所有的梯度平方，而Adadelta只累加固定大小的项，并且也不直接存储这些项，仅仅是近似计算对应的平均值。即： \n",
    "from keras.optimizers import SGD, Adadelta, Adam\n",
    "# 导入数据处理的类\n",
    "from readdata24 import DataSpeech \n",
    "\n",
    "abspath = ''  #绝对路径\n",
    "ModelName='251'  #模型名\n",
    "#NUM_GPU = 2\n",
    "\n",
    "# 声学模型\n",
    "class ModelSpeech(): # 语音模型类\n",
    "\tdef __init__(self, datapath):\n",
    "\t\t'''\n",
    "\t\t初始化\n",
    "\t\t默认输出的拼音的表示大小是1424，即1423个拼音+1个空白块\n",
    "\t\t'''\n",
    "\t\tMS_OUTPUT_SIZE = 1424   # 拼音符号的个数 1423个拼音还有一个空白符\n",
    "\t\tself.MS_OUTPUT_SIZE = MS_OUTPUT_SIZE  # 神经网络最终输出的每一个字符向量维度的大小\t(因为有1424个拼音因此,因此字符向量维度是1424)\n",
    "\t\t#self.BATCH_SIZE = BATCH_SIZE  # 一次训练的batch\n",
    "\t\tself.label_max_string_length = 64 #拼音串的最大长度,也就是说一句话不能超过这些个数的字符\n",
    "\n",
    "\t\tself.AUDIO_LENGTH = 1600   # 序列长度(转换成特征语谱图后的序列的长度)\n",
    "\n",
    "\t\tself.AUDIO_FEATURE_LENGTH = 200  #特征矩阵的长度(200维)\n",
    "\n",
    "\t\tself._model, self.base_model = self.CreateModel()   #初始化的时候调用模型创建函数进行模型的创建\n",
    "\t\t\n",
    "\t\tself.datapath = datapath  # 数据存储的的路径\n",
    "\t\tself.slash = '' #根据平台的不同进行反斜杠正斜杠的添加\n",
    "\t\tsystem_type = plat.system()  # 由于不同的系统的文件路径表示不一样，需要进行判断\n",
    "\t\tif(system_type == 'Windows'):\n",
    "\t\t\tself.slash='\\\\' # 反斜杠\n",
    "\t\telif(system_type == 'Linux'):\n",
    "\t\t\tself.slash='/' # 正斜杠\n",
    "\t\telse:\n",
    "\t\t\tprint('*[Message] Unknown System\\n')\n",
    "\t\t\tself.slash='/' # 正斜杠\n",
    "\t\tif(self.slash != self.datapath[-1]): # 在目录路径末尾增加斜杠\n",
    "\t\t\tself.datapath = self.datapath + self.slash\n",
    "\t\n",
    "\t\t\n",
    "\tdef CreateModel(self):\n",
    "\t\t'''\n",
    "\t\t定义CNN/LSTM/CTC模型，使用函数式模型\n",
    "\t\t输入层：200维的特征值序列，一条语音数据的最大长度设为1600（大约16s）\n",
    "\t\t隐藏层：卷积池化层，卷积核大小为3x3，池化窗口大小为2\n",
    "\t\t隐藏层：全连接层\n",
    "\t\t输出层：全连接层，神经元数量为self.MS_OUTPUT_SIZE，使用softmax作为激活函数，\n",
    "\t\tCTC层：使用CTC的loss作为损失函数，实现连接性时序多输出\n",
    "\t\t\n",
    "\t\t'''\n",
    "\t\t\n",
    "\t\tinput_data = Input(name='the_input', shape=(self.AUDIO_LENGTH, self.AUDIO_FEATURE_LENGTH, 1))\n",
    "\t\t\n",
    "\t\tlayer_h1 = Conv2D(32, (3,3), use_bias=False, activation='relu', padding='same', kernel_initializer='he_normal')(input_data) # 卷积层\n",
    "\t\tlayer_h1 = Dropout(0.05)(layer_h1)\n",
    "\t\tlayer_h2 = Conv2D(32, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h1) # 卷积层\n",
    "\t\tlayer_h3 = MaxPooling2D(pool_size=2, strides=None, padding=\"valid\")(layer_h2) # 池化层\n",
    "\t\t#layer_h3 = Dropout(0.2)(layer_h2) # 随机中断部分神经网络连接，防止过拟合\n",
    "\t\tlayer_h3 = Dropout(0.05)(layer_h3)\n",
    "\t\tlayer_h4 = Conv2D(64, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h3) # 卷积层\n",
    "\t\tlayer_h4 = Dropout(0.1)(layer_h4)\n",
    "\t\tlayer_h5 = Conv2D(64, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h4) # 卷积层\n",
    "\t\tlayer_h6 = MaxPooling2D(pool_size=2, strides=None, padding=\"valid\")(layer_h5) # 池化层\n",
    "\t\t\n",
    "\t\tlayer_h6 = Dropout(0.1)(layer_h6)\n",
    "\t\tlayer_h7 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h6) # 卷积层\n",
    "\t\tlayer_h7 = Dropout(0.15)(layer_h7)\n",
    "\t\tlayer_h8 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h7) # 卷积层\n",
    "\t\tlayer_h9 = MaxPooling2D(pool_size=2, strides=None, padding=\"valid\")(layer_h8) # 池化层\n",
    "\t\t\n",
    "\t\tlayer_h9 = Dropout(0.15)(layer_h9)\n",
    "\t\tlayer_h10 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h9) # 卷积层\n",
    "\t\tlayer_h10 = Dropout(0.2)(layer_h10)\n",
    "\t\tlayer_h11 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h10) # 卷积层\n",
    "\t\tlayer_h12 = MaxPooling2D(pool_size=1, strides=None, padding=\"valid\")(layer_h11) # 池化层\n",
    "\t\t\n",
    "\t\tlayer_h12 = Dropout(0.2)(layer_h12)\n",
    "\t\tlayer_h13 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h12) # 卷积层\n",
    "\t\tlayer_h13 = Dropout(0.2)(layer_h13)\n",
    "\t\tlayer_h14 = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(layer_h13) # 卷积层\n",
    "\t\tlayer_h15 = MaxPooling2D(pool_size=1, strides=None, padding=\"valid\")(layer_h14) # 池化层\n",
    "\t\t\n",
    "\t\t#test=Model(inputs = input_data, outputs = layer_h12)\n",
    "\t\t#test.summary()\n",
    "\t\t\n",
    "\t\tlayer_h16 = Reshape((200, 3200))(layer_h15) #Reshape层\n",
    "\t\t#layer_h5 = LSTM(256, activation='relu', use_bias=True, return_sequences=True)(layer_h4) # LSTM层\n",
    "\t\t#layer_h6 = Dropout(0.2)(layer_h5) # 随机中断部分神经网络连接，防止过拟合\n",
    "\t\tlayer_h16 = Dropout(0.3)(layer_h16)\n",
    "\t\tlayer_h17 = Dense(128, activation=\"relu\", use_bias=True, kernel_initializer='he_normal')(layer_h16) # 全连接层\n",
    "\t\tlayer_h17 = Dropout(0.3)(layer_h17)\n",
    "\t\tlayer_h18 = Dense(self.MS_OUTPUT_SIZE, use_bias=True, kernel_initializer='he_normal')(layer_h17) # 全连接层\n",
    "\t\t\n",
    "\t\ty_pred = Activation('softmax', name='Activation0')(layer_h18)\n",
    "\t\tmodel_data = Model(inputs = input_data, outputs = y_pred)\n",
    "\t\t#model_data.summary()\n",
    "\t\t\n",
    "\t\tlabels = Input(name='the_labels', shape=[self.label_max_string_length], dtype='float32')\n",
    "\t\tinput_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "\t\tlabel_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\t\t# Keras doesn't currently support loss funcs with extra parameters\n",
    "\t\t# so CTC loss is implemented in a lambda layer\n",
    "\t\t\n",
    "\t\t#layer_out = Lambda(ctc_lambda_func,output_shape=(self.MS_OUTPUT_SIZE, ), name='ctc')([y_pred, labels, input_length, label_length])#(layer_h6) # CTC\n",
    "\t\tloss_out = Lambda(self.ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t\n",
    "\t\tmodel = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "\t\t\n",
    "\t\tmodel.summary()\n",
    "\t\t\n",
    "\t\t# clipnorm seems to speeds up convergence\n",
    "\t\t#sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "\t\t#opt = Adadelta(lr = 0.01, rho = 0.95, epsilon = 1e-06)\n",
    "\t\topt = Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999, decay = 0.0, epsilon = 10e-8)\n",
    "\t\t#model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n",
    "\t\tmodel.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = opt)\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t# captures output of softmax so we can decode the output during visualization\n",
    "\t\ttest_func = K.function([input_data], [y_pred])\n",
    "\t\t\n",
    "\t\t#print('[*提示] 创建模型成功，模型编译成功')\n",
    "\t\tprint('[*Info] Create Model Successful, Compiles Model Successful. ')\n",
    "\t\treturn model, model_data\n",
    "\t\t\n",
    "\tdef ctc_lambda_func(self, args):\n",
    "\t\ty_pred, labels, input_length, label_length = args\n",
    "\t\t\n",
    "\t\ty_pred = y_pred[:, :, :]\n",
    "\t\t#y_pred = y_pred[:, 2:, :]\n",
    "\t\treturn K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\tdef TrainModel(self, datapath, epoch = 2, save_step = 1000, batch_size = 32, filename = abspath + 'model_speech/m' + ModelName + '/speech_model'+ModelName):\n",
    "\t\t'''\n",
    "\t\t训练模型\n",
    "\t\t参数：\n",
    "\t\t\tdatapath: 数据保存的路径\n",
    "\t\t\tepoch: 迭代轮数\n",
    "\t\t\tsave_step: 每多少步保存一次模型\n",
    "\t\t\tfilename: 默认保存文件名，不含文件后缀名\n",
    "\t\t'''\n",
    "\t\tdata=DataSpeech(datapath, 'train')\n",
    "\t\t\n",
    "\t\tnum_data = data.GetDataNum() # 获取数据的数量\n",
    "\t\t\n",
    "\t\tyielddatas = data.data_genetator(batch_size, self.AUDIO_LENGTH)\n",
    "\t\t\n",
    "\t\tfor epoch in range(epoch): # 迭代轮数\n",
    "\t\t\tprint('[running] train epoch %d .' % epoch)\n",
    "\t\t\tn_step = 0 # 迭代数据数\n",
    "\t\t\twhile True:\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tprint('[message] epoch %d . Have train datas %d+'%(epoch, n_step*save_step))\n",
    "\t\t\t\t\t# data_genetator是一个生成器函数\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t#self._model.fit_generator(yielddatas, save_step, nb_worker=2)\n",
    "\t\t\t\t\tself._model.fit_generator(yielddatas, save_step)\n",
    "\t\t\t\t\tn_step += 1\n",
    "\t\t\t\texcept StopIteration:\n",
    "\t\t\t\t\tprint('[error] generator error. please check data format.')\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\t\n",
    "\t\t\t\tself.SaveModel(comment='_e_'+str(epoch)+'_step_'+str(n_step * save_step))\n",
    "\t\t\t\tself.TestModel(self.datapath, str_dataset='train', data_count = 4)\n",
    "\t\t\t\tself.TestModel(self.datapath, str_dataset='dev', data_count = 4)\n",
    "\t\t\t\t\n",
    "\tdef LoadModel(self,filename = abspath + 'model_speech/m'+ModelName+'/speech_model'+ModelName+'.model'):\n",
    "\t\t'''\n",
    "\t\t加载模型参数\n",
    "\t\t'''\n",
    "\t\tself._model.load_weights(filename)\n",
    "\t\tself.base_model.load_weights(filename + '.base')\n",
    "\n",
    "\tdef SaveModel(self,filename = abspath + 'model_speech/m'+ModelName+'/speech_model'+ModelName,comment=''):\n",
    "\t\t'''\n",
    "\t\t保存模型参数\n",
    "\t\t'''\n",
    "\t\tself._model.save_weights(filename + comment + '.model')\n",
    "\t\tself.base_model.save_weights(filename + comment + '.model.base')\n",
    "\t\t# 需要安装 hdf5 模块\n",
    "\t\tself._model.save(filename + comment + '.h5')\n",
    "\t\tself.base_model.save(filename + comment + '.base.h5')\n",
    "\t\tf = open('step'+ModelName+'.txt','w')\n",
    "\t\tf.write(filename+comment)\n",
    "\t\tf.close()\n",
    "\n",
    "\tdef TestModel(self, datapath='', str_dataset='dev', data_count = 32, out_report = False, show_ratio = True, io_step_print = 10, io_step_file = 10):\n",
    "\t\t'''\n",
    "\t\t测试检验模型效果\n",
    "\t\t\n",
    "\t\tio_step_print\n",
    "\t\t\t为了减少测试时标准输出的io开销，可以通过调整这个参数来实现\n",
    "\t\t\n",
    "\t\tio_step_file\n",
    "\t\t\t为了减少测试时文件读写的io开销，可以通过调整这个参数来实现\n",
    "\t\t\n",
    "\t\t'''\n",
    "\t\tdata=DataSpeech(self.datapath, str_dataset)\n",
    "\t\t#data.LoadDataList(str_dataset) \n",
    "\t\tnum_data = data.GetDataNum() # 获取数据的数量\n",
    "\t\tif(data_count <= 0 or data_count > num_data): # 当data_count为小于等于0或者大于测试数据量的值时，则使用全部数据来测试\n",
    "\t\t\tdata_count = num_data\n",
    "\t\t\n",
    "\t\ttry:\n",
    "\t\t\tran_num = random.randint(0,num_data - 1) # 获取一个随机数\n",
    "\t\t\t\n",
    "\t\t\twords_num = 0\n",
    "\t\t\tword_error_num = 0\n",
    "\t\t\t\n",
    "\t\t\tnowtime = time.strftime('%Y%m%d_%H%M%S',time.localtime(time.time()))\n",
    "\t\t\tif(out_report == True):\n",
    "\t\t\t\ttxt_obj = open('Test_Report_' + str_dataset + '_' + nowtime + '.txt', 'w', encoding='UTF-8') # 打开文件并读入\n",
    "\t\t\t\n",
    "\t\t\ttxt = '测试报告\\n模型编号 ' + ModelName + '\\n\\n'\n",
    "\t\t\tfor i in range(data_count):\n",
    "\t\t\t\tdata_input, data_labels = data.GetData((ran_num + i) % num_data)  # 从随机数开始连续向后取一定数量数据\n",
    "\t\t\t\t\n",
    "\t\t\t\t# 数据格式出错处理 开始\n",
    "\t\t\t\t# 当输入的wav文件长度过长时自动跳过该文件，转而使用下一个wav文件来运行\n",
    "\t\t\t\tnum_bias = 0\n",
    "\t\t\t\twhile(data_input.shape[0] > self.AUDIO_LENGTH):\n",
    "\t\t\t\t\tprint('*[Error]','wave data lenghth of num',(ran_num + i) % num_data, 'is too long.','\\n A Exception raise when test Speech Model.')\n",
    "\t\t\t\t\tnum_bias += 1\n",
    "\t\t\t\t\tdata_input, data_labels = data.GetData((ran_num + i + num_bias) % num_data)  # 从随机数开始连续向后取一定数量数据\n",
    "\t\t\t\t# 数据格式出错处理 结束\n",
    "\t\t\t\t\n",
    "\t\t\t\tpre = self.Predict(data_input, data_input.shape[0] // 8)\n",
    "\t\t\t\t\n",
    "\t\t\t\twords_n = data_labels.shape[0] # 获取每个句子的字数\n",
    "\t\t\t\twords_num += words_n # 把句子的总字数加上\n",
    "\t\t\t\tedit_distance = GetEditDistance(data_labels, pre) # 获取编辑距离\n",
    "\t\t\t\tif(edit_distance <= words_n): # 当编辑距离小于等于句子字数时\n",
    "\t\t\t\t\tword_error_num += edit_distance # 使用编辑距离作为错误字数\n",
    "\t\t\t\telse: # 否则肯定是增加了一堆乱七八糟的奇奇怪怪的字\n",
    "\t\t\t\t\tword_error_num += words_n # 就直接加句子本来的总字数就好了\n",
    "\t\t\t\t\n",
    "\t\t\t\tif((i % io_step_print == 0 or i == data_count - 1) and show_ratio == True):\n",
    "\t\t\t\t\t#print('测试进度：',i,'/',data_count)\n",
    "\t\t\t\t\tprint('Test Count: ',i,'/',data_count)\n",
    "\t\t\t\t\n",
    "\t\t\t\t\n",
    "\t\t\t\tif(out_report == True):\n",
    "\t\t\t\t\tif(i % io_step_file == 0 or i == data_count - 1):\n",
    "\t\t\t\t\t\ttxt_obj.write(txt)\n",
    "\t\t\t\t\t\ttxt = ''\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\ttxt += str(i) + '\\n'\n",
    "\t\t\t\t\ttxt += 'True:\\t' + str(data_labels) + '\\n'\n",
    "\t\t\t\t\ttxt += 'Pred:\\t' + str(pre) + '\\n'\n",
    "\t\t\t\t\ttxt += '\\n'\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\n",
    "\t\t\t\n",
    "\t\t\t#print('*[测试结果] 语音识别 ' + str_dataset + ' 集语音单字错误率：', word_error_num / words_num * 100, '%')\n",
    "\t\t\tprint('*[Test Result] Speech Recognition ' + str_dataset + ' set word error ratio: ', word_error_num / words_num * 100, '%')\n",
    "\t\t\tif(out_report == True):\n",
    "\t\t\t\ttxt += '*[测试结果] 语音识别 ' + str_dataset + ' 集语音单字错误率： ' + str(word_error_num / words_num * 100) + ' %'\n",
    "\t\t\t\ttxt_obj.write(txt)\n",
    "\t\t\t\ttxt = ''\n",
    "\t\t\t\ttxt_obj.close()\n",
    "\t\t\t\n",
    "\t\texcept StopIteration:\n",
    "\t\t\tprint('[Error] Model Test Error. please check data format.')\n",
    "\t\n",
    "\tdef Predict(self, data_input, input_len):\n",
    "\t\t'''\n",
    "\t\t预测结果\n",
    "\t\t返回语音识别后的拼音符号列表\n",
    "\t\t'''\n",
    "\t\t\n",
    "\t\tbatch_size = 1 \n",
    "\t\tin_len = np.zeros((batch_size),dtype = np.int32)\n",
    "\t\t\n",
    "\t\tin_len[0] = input_len\n",
    "\t\t\n",
    "\t\tx_in = np.zeros((batch_size, 1600, self.AUDIO_FEATURE_LENGTH, 1), dtype=np.float)\n",
    "\t\t\n",
    "\t\tfor i in range(batch_size):\n",
    "\t\t\tx_in[i,0:len(data_input)] = data_input\n",
    "\t\t\n",
    "\t\t\n",
    "\t\tbase_pred = self.base_model.predict(x = x_in)\n",
    "\t\t\n",
    "\t\t#print('base_pred:\\n', base_pred)\n",
    "\t\t\n",
    "\t\t#y_p = base_pred\n",
    "\t\t#for j in range(200):\n",
    "\t\t#\tmean = np.sum(y_p[0][j]) / y_p[0][j].shape[0]\n",
    "\t\t#\tprint('max y_p:',np.max(y_p[0][j]),'min y_p:',np.min(y_p[0][j]),'mean y_p:',mean,'mid y_p:',y_p[0][j][100])\n",
    "\t\t#\tprint('argmin:',np.argmin(y_p[0][j]),'argmax:',np.argmax(y_p[0][j]))\n",
    "\t\t#\tcount=0\n",
    "\t\t#\tfor i in range(y_p[0][j].shape[0]):\n",
    "\t\t#\t\tif(y_p[0][j][i] < mean):\n",
    "\t\t#\t\t\tcount += 1\n",
    "\t\t#\tprint('count:',count)\n",
    "\t\t\n",
    "\t\tbase_pred =base_pred[:, :, :]\n",
    "\t\t#base_pred =base_pred[:, 2:, :]\n",
    "\t\t\n",
    "\t\tr = K.ctc_decode(base_pred, in_len, greedy = True, beam_width=100, top_paths=1)\n",
    "\t\t\n",
    "\t\t#print('r', r)\n",
    "\t\t\n",
    "\t\t\n",
    "\t\tr1 = K.get_value(r[0][0])\n",
    "\t\t#print('r1', r1)\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t#r2 = K.get_value(r[1])\n",
    "\t\t#print(r2)\n",
    "\t\t\n",
    "\t\tr1=r1[0]\n",
    "\t\t\n",
    "\t\treturn r1\n",
    "\t\tpass\n",
    "\t\n",
    "\tdef RecognizeSpeech(self, wavsignal, fs):\n",
    "\t\t'''\n",
    "\t\t最终做语音识别用的函数，识别一个wav序列的语音\n",
    "\t\t不过这里现在还有bug\n",
    "\t\t'''\n",
    "\t\t\n",
    "\t\t#data = self.data\n",
    "\t\t#data = DataSpeech('E:\\\\dataset')\n",
    "\t\t#data.LoadDataList('dev')\n",
    "\t\t# 获取输入特征\n",
    "\t\t#data_input = GetMfccFeature(wavsignal, fs)\n",
    "\t\t#t0=time.time()\n",
    "\t\tdata_input = GetFrequencyFeature3(wavsignal, fs)\n",
    "\t\t#t1=time.time()\n",
    "\t\t#print('time cost:',t1-t0)\n",
    "\t\t\n",
    "\t\tinput_length = len(data_input)\n",
    "\t\tinput_length = input_length // 8\n",
    "\t\t\n",
    "\t\tdata_input = np.array(data_input, dtype = np.float)\n",
    "\t\t#print(data_input,data_input.shape)\n",
    "\t\tdata_input = data_input.reshape(data_input.shape[0],data_input.shape[1],1)\n",
    "\t\t#t2=time.time()\n",
    "\t\tr1 = self.Predict(data_input, input_length)\n",
    "\t\t#t3=time.time()\n",
    "\t\t#print('time cost:',t3-t2)\n",
    "\t\tlist_symbol_dic = GetSymbolList(self.datapath) # 获取拼音列表\n",
    "\t\t\n",
    "\t\t\n",
    "\t\tr_str=[]\n",
    "\t\tfor i in r1:\n",
    "\t\t\tr_str.append(list_symbol_dic[i])\n",
    "\t\t\n",
    "\t\treturn r_str\n",
    "\t\tpass\n",
    "\t\t\n",
    "\tdef RecognizeSpeech_FromFile(self, filename):\n",
    "\t\t'''\n",
    "\t\t最终做语音识别用的函数，识别指定文件名的语音\n",
    "\t\t'''\n",
    "\t\t\n",
    "\t\twavsignal,fs = read_wav_data(filename)\n",
    "\t\t\n",
    "\t\tr = self.RecognizeSpeech(wavsignal, fs)\n",
    "\t\t\n",
    "\t\treturn r\n",
    "\t\t\n",
    "\t\tpass\n",
    "\t\t\n",
    "\t\n",
    "\t\t\n",
    "\t@property\n",
    "\tdef model(self):\n",
    "\t\t'''\n",
    "\t\t返回keras model\n",
    "\t\t'''\n",
    "\t\treturn self._model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 1600, 200, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 1600, 200, 32 288         the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1600, 200, 32 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 1600, 200, 32 9248        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 800, 100, 32) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 800, 100, 32) 0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 800, 100, 64) 18496       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 800, 100, 64) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 800, 100, 64) 36928       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 400, 50, 64)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 400, 50, 64)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 400, 50, 128) 73856       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 400, 50, 128) 0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 400, 50, 128) 147584      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 200, 25, 128) 0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 200, 25, 128) 0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 200, 25, 128) 147584      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 200, 25, 128) 0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 200, 25, 128) 147584      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 200, 25, 128) 0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 200, 25, 128) 0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 200, 25, 128) 147584      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 200, 25, 128) 0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 200, 25, 128) 147584      dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 200, 25, 128) 0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 200, 3200)    0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 200, 3200)    0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 200, 128)     409728      dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 200, 128)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 200, 1424)    183696      dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Activation0 (Activation)        (None, 200, 1424)    0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           Activation0[0][0]                \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,470,160\n",
      "Trainable params: 1,470,160\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[*Info] Create Model Successful, Compiles Model Successful. \n",
      "[running] train epoch 0 .\n",
      "[message] epoch 0 . Have train datas 0+\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "if(__name__=='__main__'):\n",
    "\t\n",
    "\t#import tensorflow as tf\n",
    "\t#from keras.backend.tensorflow_backend import set_session\n",
    "\t#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\t#进行配置，使用95%的GPU\n",
    "\t#config = tf.ConfigProto()\n",
    "\t#config.gpu_options.per_process_gpu_memory_fraction = 0.95\n",
    "\t#config.gpu_options.allow_growth=True   #不全部占满显存, 按需分配\n",
    "\t#set_session(tf.Session(config=config))\n",
    "\t\n",
    "\t\n",
    "\tdatapath =  abspath + ''\n",
    "\tmodelpath =  abspath + 'model_speech'\n",
    "\t\n",
    "\t\n",
    "\tif(not os.path.exists(modelpath)): # 判断保存模型的目录是否存在\n",
    "\t\tos.makedirs(modelpath) # 如果不存在，就新建一个，避免之后保存模型的时候炸掉\n",
    "\t\n",
    "\tsystem_type = plat.system() # 由于不同的系统的文件路径表示不一样，需要进行判断\n",
    "\tif(system_type == 'Windows'):\n",
    "\t\tdatapath = 'Z:\\\\dataset'\n",
    "\t\tmodelpath = modelpath + '\\\\'\n",
    "\telif(system_type == 'Linux'):\n",
    "\t\tdatapath =  abspath + 'dataset'\n",
    "\t\tmodelpath = modelpath + '/'\n",
    "\telse:\n",
    "\t\tprint('*[Message] Unknown System\\n')\n",
    "\t\tdatapath = 'dataset'\n",
    "\t\tmodelpath = modelpath + '/'\n",
    "\t\n",
    "\tms = ModelSpeech(datapath)\n",
    "\t\n",
    "\t\n",
    "\t#ms.LoadModel(modelpath + 'm251/speech_model251_e_0_step_100000.model')\n",
    "\tms.TrainModel(datapath, epoch = 50, batch_size = 16, save_step = 500) \n",
    "\t\n",
    "\t#下面是本文件的测试\n",
    "\tt1=time.time()\n",
    "\tms.TestModel(datapath, str_dataset='train', data_count = 128, out_report = True)\n",
    "\t#ms.TestModel(datapath, str_dataset='dev', data_count = 128, out_report = True)\n",
    "\t#ms.TestModel(datapath, str_dataset='test', data_count = 128, out_report = True)\n",
    "\tt2=time.time()\n",
    "\tprint('Test Model Time Cost:',t2-t1,'s')\n",
    "\t#r = ms.RecognizeSpeech_FromFile('E:\\\\dataset\\\\ST-CMDS-20170001_1-OS\\\\20170001P00241I0053.wav')\n",
    "\t#r = ms.RecognizeSpeech_FromFile('E:\\\\dataset\\\\ST-CMDS-20170001_1-OS\\\\20170001P00020I0087.wav')\n",
    "\t#r = ms.RecognizeSpeech_FromFile('E:\\\\dataset\\\\wav\\\\train\\\\A11\\\\A11_167.WAV')\n",
    "\t#r = ms.RecognizeSpeech_FromFile('E:\\\\dataset\\\\wav\\\\test\\\\D4\\\\D4_750.wav')\n",
    "\t#print('*[提示] 语音识别结果：\\n',r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
